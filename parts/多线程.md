- [首页](../README.md "Java Interview Docs")
1. InheritableThreadLocal实现原理
   - 子线程是通过在父线程中通过调用new Thread()方法来创建子线程
   - Thread#init方法在Thread的构造方法中被调用,在init方法中拷贝父线程数据到子线程中
2. AQS 核心思想
   - 如果被请求的共享资源空闲,则将当前请求资源的线程设置为有效的工作线程,并且将共享资源设置为锁定状态。
   - 如果被请求的共享资源被占用,那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制,这个机制AQS 是基于 CLH 锁实现的。
   - CLH 锁是对自旋锁的一种改进,是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例,仅存在结点之间的关联关系),暂时获取不到锁的线程将被加入到该队列中。
     AQS 将每条请求共享资源的线程封装成一个 CLH 队列锁的一个结点(Node)来实现锁的分配。
   - 在 CLH 队列锁中,一个节点表示一个线程,它保存着线程的引用(thread)、
     当前节点在队列中的状态(waitStatus)、前驱节点(prev)、后继节点(next)
   - AQS 使用了模板方法模式,自定义同步器时需要重写AQS提供的钩子方法
   - 当线程释放锁时，AQS 会调用 tryRelease(int arg) 方法来尝试释放锁。如果释放成功，AQS 会检查同步队列中的其他线程，唤醒排在队列中的下一个线程，尝试让它获取锁
3. synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源,而Semaphore(信号量)可以用来控制同时访问特定资源的线程数量
4. Completablefuture常用方法thenApply(),thenAccept(),thenCompose(),thenCombine(),allof()
5. Java 线程的本质其实就是操作系统的内核线程
6. 为什么 wait()方法不定义在 Thread 中?
    - 每个对象(Object)都拥有对象锁,wait()是让获得对象锁的线程实现等待,自动释放当前线程占有的对象锁
    - 类似的问题:为什么 sleep()方法定义在 Thread 中?
        - 因为 sleep()是让当前线程暂停执行,不涉及到对象类,也不需要获得对象锁。
7. Java 使用的线程调度是抢占式的。
    - JVM本身不负责线程的调度,而是将线程的调度委托给操作系统。
    - 操作系统通常会基于线程优先级和时间片来调度线程的执行,高优先级的线程通常获得 CPU时间片的机会更多
8. 锁主要存在四种状态,依次是:无锁状态、偏向锁状态、轻量级锁状态、重量级锁(在JDK18中,偏向锁已经被彻底废弃)
9. 锁的升级顺序
   - 无锁：对象头（Mark Word）中无线程 ID、无锁记录，没有任何同步竞争
   - 偏向锁：JDK ≤ 14默认开启，单线程反复进入 synchronized，那就不要再做 CAS 竞争了，Mark Word 中记录偏向标志、持有锁的线程 ID
   - 轻量级锁：线程栈中创建 Lock Record，使用 CAS 尝试将对象 Mark Word → 指向 Lock Record。适合短时间、低竞争，线程自旋（Spin）不会立刻阻塞
   - 重量级锁：线程挂起（进入内核态），上下文切换成本，但在高竞争下更稳定
10. 偏向锁为何被废弃
    - 实际收益远低于预期：在现实系统中锁被不同线程交替使用是常态，导致偏向锁频繁撤销，撤销成本 > 直接轻量级锁
    - 偏向锁撤销是“STW 操作”：全局安全点（Safepoint），扫描线程栈，修正对象头。在高并发系统中，这是不可接受的
11. 如何跨线程传递 ThreadLocal 的值?
     - InheritableThreadLocal:会在创建子线程时,令子线程继承父线程中的ThreadLocal值,但是无法支持线程池场景下的 ThreadLocal 值传递。
     - TransmittableThreadLocal:可以在线程池的场景下支持 ThreadLocal 值传递。(装饰器模式)
12. TransmittableThreadLocal实现原理
    - 实现自定义的 Thread,在run()方法内部做 ThreadLocal 变量的赋值操作
    - 基于 线程池 进行装饰,在execute()方法中,不提交 JDK 内部的Thread,而是提交自定义的 Thread
13. poll和epoll的区别
    - **操作方式**: `poll` 每次调用都要把所有 fd 拷贝到内核，并轮询所有 fd (O(N))。`epoll` 在 `epoll_ctl` 时注册 fd，一旦 fd 就绪会通过回调加入就绪链表，`epoll_wait` 只返回就绪的 fd (O(1))。
    - **数据结构**: `poll` 使用链表/数组，`epoll` 使用红黑树管理 fd，就绪队列使用双向链表。
    - **并发限制**: `poll` 无最大连接数限制（受限于系统资源），但数量大时性能下降明显。`epoll` 适合高并发连接，性能不会随连接数增加而显著下降（只与活跃连接数有关）。
    - **触发模式**: `epoll` 支持边缘触发 (ET) 和水平触发 (LT)，`poll` 只支持水平触发。
14. ThreadLocal原理
    - 每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为 key ，Object 对象为 value 的键值对。
    ```
    Thread
     ├── threadLocals : ThreadLocalMap
     │
     │   ThreadLocalMap
     │   ├── table[] : Entry[]
     │   │
     │   │   Entry (继承自 WeakReference<ThreadLocal>)
     │   │   ├── key   : ThreadLocal<?> (弱引用)
     │   │   └── value : Object
     │   │
     │   ├── Entry[0] →  key: ThreadLocalA  | value: A对象
     │   ├── Entry[1] →  key: ThreadLocalB  | value: B对象
     │   └── Entry[2] →  key: ThreadLocalC  | value: C对象
     │
     └── inheritableThreadLocals : ThreadLocalMap （可选，继承父线程）
    ```
15. ThreadLocal 内存泄露问题是怎么导致的？
    - ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。
    - 所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。
    - 这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。
    - ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。
    - 使用完 ThreadLocal方法后最好手动调用remove()方法
16. ThreadLocalMap 的 key 为什么不设计为 ThreadLocal 的强引用
    - 避免“Thread → ThreadLocalMap → ThreadLocal”形成强引用链导致 ThreadLocal 无法被 GC，从而产生更隐蔽、更难排查的内存泄漏
    - ThreadLocalMap 是 Thread 的成员变量，生命周期往往和线程一致（尤其是线程池）
17. 那为什么 ThreadLocalMap 的 value 不设计成弱引用
    - 如果 value 是弱引用，下一次 GC 只要没有其他强引用 value 就会被回收，可能突然返回 null，这将彻底破坏 ThreadLocal 的语义
18. ThreadPoolExecutor重要的参数
    - corePoolSize : 任务队列未达到队列容量时，最大可以同时运行的线程数量。
    - maximumPoolSize : 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
    - workQueue: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
      - ArrayBlockingQueue：适用于固定任务量的场景
      - LinkedBlockingQueue：适用于任务量不可预测的场景
      - PriorityBlockingQueue：适用于任务有优先级的场景
      - DelayQueue：适用于需要延迟执行任务的场景
19. 线程池的拒绝策略有哪些？
    - ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。
    - ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果你的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
    - ThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃掉。
    - ThreadPoolExecutor.DiscardOldestPolicy：此策略将丢弃最早的未处理的任务请求。
20. CallerRunsPolicy 拒绝策略有什么风险？如何解决？
    - 如果走到CallerRunsPolicy的任务是个非常耗时的任务，且处理提交任务的线程是主线程，可能会导致主线程阻塞，影响程序的正常运行。
    - 从问题的本质入手，调用者采用CallerRunsPolicy是希望所有的任务都能够被执行，暂时无法处理的任务又被保存在阻塞队列BlockingQueue中。这样的话，在内存允许的情况下，我们可以增加阻塞队列BlockingQueue的大小并调整堆内存以容纳更多的任务，确保任务能够被准确执行。为了充分利用 CPU，我们还可以调整线程池的maximumPoolSize （最大线程数）参数，这样可以提高任务处理速度，避免累计在 BlockingQueue的任务过多导致内存用完。
    - 如果服务器资源以达到可利用的极限，这就意味我们要在设计策略上改变线程池的调度了，我们都知道，导致主线程卡死的本质就是因为我们不希望任何一个任务被丢弃。
    - 换个思路，有没有办法既能保证任务不被丢弃且在服务器有余力时及时处理呢？这里提供的一种任务持久化的思路，这里所谓的任务持久化，包括但不限于:
      - 设计一张任务表将任务存储到 MySQL 数据库中。
      - Redis 缓存任务。
      - 将任务提交到消息队列中。
21. 如何设定线程池的大小？
    - CPU 密集型任务(N+1)： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。
      - 比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。
      - 一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。
    - I/O 密集型任务(2N)： 这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。
22. Future 类有什么用？
    - Future 类是异步思想的典型运用，主要用在一些需要执行耗时任务的场景，避免程序一直原地等待耗时任务执行完成，执行效率太低。
    - 具体来说是这样的：当我们执行某一耗时的任务时，可以将这个耗时任务交给一个子线程去异步执行，同时我们可以干点其他事情，不用傻傻等待耗时任务执行完成。
    - 等我们的事情干完后，我们再通过 Future 类获取到耗时任务的执行结果。这样一来，程序的执行效率就明显提高了。

- [首页](../README.md "Java Interview Docs")
1. CAP 定理(CAP theorem)指出对于一个分布式系统来说,当设计读写操作时,只能同时满足以下三点中的两个:
   - 一致性(Consistency):所有节点访问同一份最新的数据副本
   - 可用性(Availability):非故障的节点在合理的时间内返回合理的响应(不是错误或者超时的响应)。
   - 分区容错性(Partition Tolerance):分布式系统出现网络分区的时候,仍然能够对外提供服务。
   - ZooKeeper是 CP 架构，Eureka 就是 AP 架构，Nacos 支持 CP 架构也支持 AP 架构
2. Spring Cloud Gateway 和 Zuul 2.x 的差别不大,也是通过过滤器来处理请求。  
   - 更推荐使用 Spring Cloud Gateway 而非 Zuul,Spring Cloud 生态对其支持更加友好。
3. 常用的网关有 Spring Cloud Gateway、Kong、APISIX
   - Spring Cloud Gateway：底层基于Java (Netty / WebFlux)实现，QPS中等（万级）
   - Kong：底层基于Nginx (OpenResty / Lua)实现，QPS高（十万级）
   - Apache APISIX：底层基于Nginx + etcd实现，QPS极高（十万至百万级）
4. Spring Cloud Gateway 的工作流程?
   - 路由判断:客户端的请求到达网关后先经过 Gateway Handler Mapping 处理,里面会做断言(Predicate)判断看符合哪个路由规则,这个路由映射后端的某个服务
   - Pre-Filters->后端服务对请求进行处理 ->Post-Filters
5. Spring Cloud Gateway 如何实现动态路由?
   - 基于 Nacos 注册中心,从注册中心获取服务的元数据(例如服务名称、路径等),然后根据这些信息自动生成路由规则
6. Spring Cloud Gateway如何基于ip或者userId进行定向路由
   - 实现自定义KeyResolver Bean，在route中指定它
7. UUID 的优缺点:存储消耗空间大/无序(非自增)会严重影响数据库性能
8. 分布式id生成方式有哪些?
    - **Snowflake雪花算法**
      - 不依赖外部数据库，完全在内存中生成。
      - 生成的是一个 64 位的 Long 型整数，结构如下： 
        - 1位符号位：固定为 0，保证 ID 为正数。 
        - 41位毫秒时间戳：约可支持 69 年。 
        - 10位机器 ID：支持 1024 个节点。通常分为 5 位 DataCenterId 和 5 位 WorkerId。 
        - 12位序列号：同一毫秒内的计数，支持每毫秒生成 4096 个 ID。
    - **基于 Redis 的原子递增**
      - 利用 Redis 的 INCR 或 INCRBY 原子操作来生成 ID。
      - 由于 Redis 是单线程执行命令的（即使 6.0+ 也是原子执行），可以保证并发下的唯一性。
      - 为了减少网络请求，可以一次递增 1000（INCRBY key 1000），然后在 Java 应用本地内存中使用 AtomicLong 慢慢消化这 1000 个号。
    - **基于数据库的号段模式**
      - 在数据库中存一张表，记录每个业务当前的 max_id 和 step（步长）。 
      - Java 服务端启动时，去数据库“批发”一个号段（比如 10000-20000），并将 max_id 更新为 20000。 
      - 本地消费：服务端在内存中通过 AtomicLong 逐个分发这 10000 个号。 
      - 异步加载（双 Buffer 优化）：当号段用到 80% 时，异步开启线程去数据库领下一个号段，确保业务无感知切换。
9. 基于数据库的号段模式时，如何防止并发请求获取到同一批号段
   - 使用乐观锁，通过在更新 SQL 中加入旧值校验，利用数据库行级锁的原子性来确保只有一个实例能更新成功
   ````sql
   UPDATE id_generator 
    SET max_id = max_id + step,
    update_time = NOW()
    WHERE biz_tag = 'order_id'
    AND max_id = ?  -- 刚查询到的旧 max_id
   ````
   - 节点 A 和 节点 B 同时 Select 到了 max_id = 10000。
   - 节点 A 先执行 Update，执行成功，受影响行数为 1。它拿到了 [10001, 20000]。
   - 节点 B 随后执行 Update，由于此时数据库里的 max_id 已经变成了 20000，其 WHERE max_id = 10000 条件不成立，受影响行数为 0。
   - 节点 B 更新失败，重新触发“查询 -> 尝试更新”的循环（自旋），直到成功拿走下一个号段 [20001, 30000]。
10. 分布式锁的常见实现方式有哪些?
     - 基于关系型数据库比如 MySQL 实现分布式锁。
     - 基于分布式协调服务 ZooKeeper 实现分布式锁。
     - 基于分布式键值存储系统比如 Redis、Etcd 实现分布式锁。
11. 如何基于关系型数据库比如 MySQL 实现分布式锁
    - 基于唯一索引（简单粗暴）：利用数据库的 UNIQUE KEY 约束，确保同一时刻只能插入一条记录
      - 加锁：直接 INSERT 一条记录。如果返回成功，则获得锁；如果抛出 Duplicate Key 异常，则说明锁已被占用。
      - 解锁：DELETE FROM method_lock WHERE method_name = 'xxx' AND node_info = 'yyy';
      - 缺点：不支持重入（加锁节点再次请求会失败），且如果节点宕机，锁可能永远无法释放（需要后台线程定时清理 expire_time）
        - 解决：在表中增加 count 字段。加锁时判断 node_info 是否为自己，如果是则 count + 1，解锁时 count - 1，直到为 0 时真正删除记录。
    ````sql
    CREATE TABLE `method_lock` (
    `id` int(11) NOT NULL AUTO_INCREMENT,
    `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名或资源名',
    `node_info` varchar(64) NOT NULL COMMENT '持有锁的节点信息',
    `expire_time` timestamp NULL COMMENT '过期时间',
    PRIMARY KEY (`id`),
    UNIQUE KEY `uidx_method_name` (`method_name`) -- 核心：唯一索引
    ) ENGINE=InnoDB;
    ````
    - 基于 FOR UPDATE（最标准的做法）
      - 天然支持锁的自动释放（连接断开或事务结束，锁自动解开）。
      - 加锁流程：
        - 开启事务：SET autocommit=0;
        - 查询并加锁：SELECT * FROM method_lock WHERE method_name = 'xxx' FOR UPDATE;
        - 如果返回了记录且成功加锁，则执行业务逻辑。
        - 如果没拿到（被阻塞或超时），则加锁失败。
      - 解锁：直接 COMMIT 或 ROLLBACK 事务。
      - FOR UPDATE 在同一个事务内可以重入，在同一个 @Transactional 方法内多次调用加锁逻辑，它是不会阻塞的。
      - 但是如果在同一个java线程中开启了两个不同的事务（对应两个不同的数据库连接），就会造成死锁，通常需要在应用层增加 ThreadLocal 计数器去解决
12. Redisson提供了一个专门用来监控和续期锁的Watch Dog(看门狗),默认情况下,每过10秒,看门狗就会执行续期操作,将锁的超时时间设置为30 秒
    - 只要加锁时没传 leaseTime 参数，Redisson 就会默认开启看门狗
    - 它是一个基于 Netty 的 HashedWheelTimer（时间轮）实现的定时任务
13. Redisson的分布式锁原理
    - Redisson 并不像简单的 Redis 锁那样只存一个 String，它存储的是一个 Hash。
      - Key: 锁的名字（如 myLock）。
      - Field: UUID:ThreadId（每个 Redisson 客户端实例有一个唯一的 UUID，配合线程 ID 确保全局唯一）。
        - 为什么要加 UUID？如果只用 Thread ID，不同的 Java 进程（JVM）中可能存在 ID 相同的线程。因此，Redisson 内部维护了一个 ConnectionManager，它在启动时生成一个 UUID
      - Value: 计数器（Integer），用于记录 重入次数。
    - Redisson 在加锁时会向 Redis 发送一段 Lua 脚本
      - 如果锁不存在，创建 Hash，设置 Field 为 ThreadID，Value 为 1，设置过期时间（默认 30 秒）
      - 如果锁已存在，判断持有者是否是当前线程（实现重入）
14. Redlock 算法的思想
    - 让客户端向 Redis 集群中的多个独立的 Redis 实例依次请求申请加锁,
    - 如果客户端能能够和半数以上的实例成功地完成加锁操作,那么我们就认为,客户端成功地获得分布式锁,否则加锁失败
15. Seata的AT模式两阶段提交和传统的两阶段提交有什么区别?
    - AT模式的一阶段会提交业务数据和记录undo log,释放本地锁和资源。
    - Seata会拦截业务sq1,生成before和after image,最后生成行锁。
    - 二阶段如果确认成功,TC会通知RM异步删除undo log和行锁。如果失败,TM会向TC发起回滚请求,TC通知RM根据XID和branch id找到对应的undo 1og进行回滚。
    - 在AT模式中,参与者的本地事务执行成功后即可提交,而不需要等待其他参与者的状态
16. Seata AT 模式下，默认的隔离级别是“读未提交（Read Uncommitted），怎么防止脏读和脏写
    - 核心机制：全局锁 @GlobalLock 注解
    - 如果要求某个查询必须读取到“最终确认”的数据，需要给这个查询方法加上 @GlobalLock 注解，或者使用 SELECT ... FOR UPDATE。
      - 当一个事务尝试 SELECT ... FOR UPDATE 时，Seata 的代理数据源会拦截这个请求。
      - 它会去 TC（事务协调器） 询问：当前这行数据是否被其他正在运行的分布式事务锁定了？
      - 如果 TC 说“这行数据有全局锁”，说明有一个分布式事务正在处理这行，还没最终确认。
      - 阻塞等待：当前的查询操作会原地自旋等待，直到那个分布式事务完成二阶段（提交或回滚）并释放全局锁。
17. Seata中全局锁和本地锁的区别
    - 本地行锁（DB Lock）：在一阶段提交时就释放了。这样做是为了让本地数据库的资源能够快速回收，提高吞吐量。
    - 全局锁（Global Lock）：由 Seata TC 管理。它从一阶段开始持有，直到二阶段（无论是提交还是回滚）结束后才释放。实现分布式下的“读已提交（Read Committed）”。
    - 在大多数非金融核心业务中，轻微的“脏读”是可以容忍的（因为二阶段失败回滚是极低概率事件）。此时直接使用普通 SELECT，性能不受影响
    - 对于对账、库存扣减等敏感查询，必须在查询方法上加上 @GlobalLock，Seata AT 模式通过全局锁将隔离级别从“读未提交”提升到“读已提交”
18. JWT 结构
    - Header：签名所使用的算法、令牌类型（一般为 JWT），然后将它进行 Base64URL 编码，得到 JWT 的第一部分
    - Payload：存放需要传递的 声明（Claims），如用户信息、权限、过期时间等
    - Signature：用于验证令牌的完整性和可信性，防止内容被篡改（前面两部分内容加起来进行加密）
19. JWT 的优势
    - 无状态：JWT 自身包含了身份验证所需要的所有信息，因此，我们的服务器不需要存储 Session 信息
    - 有效避免了 CSRF 攻击：CSRF 攻击需要依赖 Cookie，JWT存放在 localStorage 中。前端的每一个请求后续都会附带上这个 JWT，整个过程压根不会涉及到 Cookie。不过，这样也会存在 XSS 攻击的风险，在 Spring 项目中，我们一般是通过创建 XSS 过滤器来避免XSS。
    - 适合移动端应用：Session 基于服务器端的状态管理，而移动端应用通常是无状态的。
20. JWT 身份认证常见问题及解决办法
    - 注销登录等场景下 JWT 还有效：JWT 一旦派发出去，如果后端不增加其他逻辑的话，它在失效之前都是有效的。
      - 解决方式：将 JWT 存入redis或黑名单机制，每次先对比
    - JWT 的续签问题：JWT 有效期一般都建议设置的不太长，那么 JWT 过期后如何认证，如何实现动态刷新 JWT，避免用户经常需要重新登录？
      - 解决方式：用户登录返回两个 JWT（推荐）：客户端登录后，将 accessJWT 和 refreshJWT 保存在本地，每次访问将 accessJWT 传给服务端。服务端校验 accessJWT 的有效性，如果过期的话，就将 refreshJWT 传给服务端。如果有效，服务端就生成新的 accessJWT 给客户端。否则，客户端就重新登录即可。
21. 如何跨域登录、登出？ 
    - 解决跨域的核心思路就是解决 Cookie 的跨域读写AuthToken问题
    - 登录完成之后通过回调的方式，将 AuthToken 传递给主域名之外的站点，该站点自行将 AuthToken 保存在当前域下的 Cookie 中。
    - 登出完成之后通过回调的方式，调用非主域名站点的登出页面，完成设置 Cookie 中的 AuthToken 过期的操作。
22. 权限模型有哪些？
    - 基于角色的访问控制（RBAC）：一个用户可以拥有若干角色，每一个角色又可以被分配若干权限
    - 基于属性的访问控制（ABAC）：是一种比 RBAC模型 更加灵活的授权模型，它的原理是通过各种属性来动态判断一个操作是否可以被允许。这个模型在云系统中使用的比较多，比如 AWS，阿里云等。
    - RBAC1（角色继承）：角色之间有等级关系。例如，“HR 总监”角色继承自“HR 专员”，拥有其所有权限。 
    - RBAC2（静态/动态职责分离）：引入约束。 
      - 互斥角色：同一个用户不能同时拥有“会计”和“审计”角色（防范舞弊）。 
      - 基数约束：一个角色下的用户数量有限制（如：CEO 角色只能给 1 个人）。 
    - RBAC3（统一模型）：即 RBAC1 + RBAC2 的组合。
23. BASE 是 Basically Available（基本可用）、Soft-state（软状态） 和 Eventually Consistent（最终一致性） 三个短语的缩写。
    - BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。
24. Zookeeper选举leader过程
    - 前提： ZK 使用 ZAB 协议（类似 Paxos），每个服务器都有 (sid, zxid)
      - sid：服务器 ID
      - zxid：最后事务 ID，用于比较谁的数据最新（zxid 是一个 64 位数字，高 32 位是 epoch（领导者任期号），低 32 位是该epoch内的事务计数器）
    - 服务器启动或 Leader 崩溃 → 进入 LOOKING 状态
    - 每个节点投票给自己（(my_sid, my_zxid)），把自己的投票广播给所有其他节点
    - 每个节点收到别人投票后，会按以下顺序比较选票： 
      - zxid 大的优先（数据更新越新越优先） 
      - 若 zxid 相同 → sid 大的优先
    - 若对方更优 → 更新自己的投票为更优的 (sid, zxid)，并继续广播更新后的投票
    - 若某个投票获得半数以上节点支持 → 选举成功，该投票的 sid 被选为 Leader，其他节点变为 Follower / Observer
    - 状态同步：Follower节点与Leader同步状态，同步完成后Leader开始处理客户端请求
25. Gossip 协议
    - 在 Gossip 协议下，没有所谓的中心节点，每个节点周期性地随机找一个节点互相同步彼此的信息，理论上来说，各个节点的状态最终会保持一致。
    - 有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时可以自动切换。
26. 什么是API网关？
    - 网关主要做了两件事情：请求转发 + 请求过滤（安全认证（身份/权限认证）、流量控制、负载均衡、降级熔断、日志、监控、参数校验、协议转换）。
27. 常见的网关Spring Cloud Gateway和Zuul
    - Zuul 主要通过过滤器（类似于 AOP）来过滤请求，从而实现网关必备的各种功能。
    - Spring Cloud Gateway 和 Zuul 2.x 的差别不大，也是通过过滤器来处理请求。
    - 不过，目前更加推荐使用 Spring Cloud Gateway 而非 Zuul，Spring Cloud 生态对其支持更加友好。底层基于 Netty 实现同步非阻塞的 I/O。
28. 分布式锁的常见实现方式有哪些？
    - 基于关系型数据库比如 MySQL 实现分布式锁。
    - 基于分布式协调服务 ZooKeeper 实现分布式锁。
    - 基于分布式键值存储系统比如 Redis 、Etcd 实现分布式锁。
29. Redis分布式锁
    - 如果操作共享资源的时间大于过期时间，就会出现锁提前过期的问题，进而导致分布式锁直接失效。如果锁的超时时间设置过长，又会影响到性能。
    - 可以使用Redisson中的分布式锁自带自动续期机制，原理也比较简单，其提供了一个专门用来监控和续期锁的 Watch Dog（ 看门狗），如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。
    - Redisson本身内置了多种类型的锁比如可重入锁（Reentrant Lock）、自旋锁（Spin Lock）、公平锁（Fair Lock）、多重锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）。
30. 基于 ZooKeeper 实现分布式锁
    - ZooKeeper 分布式锁是基于 临时顺序节点 和 Watcher（事件监听器） 实现的
    - 首先我们要有一个持久节点/locks，客户端获取锁就是在locks下创建临时顺序节点。
    - 假设客户端 1 创建了/locks/lock1节点，创建成功之后，会判断 lock1是否是 /locks 下最小的子节点。
    - 如果 lock1是最小的子节点，则获取锁成功。否则，获取锁失败。如果获取锁失败，则说明有其他的客户端已经成功获取锁。客户端 1 并不会不停地循环去尝试加锁，而是在前一个节点比如/locks/lock0上注册一个事件监听器。这个监听器的作用是当前一个节点释放锁之后通知客户端 1（避免无效自旋），这样客户端 1 就加锁成功了。
    - 临时节点的生命周期是与 客户端会话（session） 绑定的，会话消失则节点消失，不会发生死锁的问题。
31. RPC //todo
32. SPI（Service Provider Interface） 的具体原理是这样的：我们将接口的实现类放在配置文件中，我们在程序运行过程中读取配置文件，通过反射加载实现类。这样，我们可以在运行的时候，动态替换接口的实现类。和 IoC 的解耦思想是类似的。
33. Dubbo 提供的负载均衡策略有哪些？
    - 根据权重随机选择（对加权随机算法的实现）。这是 Dubbo 默认采用的一种负载均衡策略。
      - 假如有两个提供相同服务的服务器 S1,S2，S1 的权重为 7，S2 的权重为 3。
      - 我们把这些权重值分布在坐标区间会得到：S1->[0, 7) ，S2->[7, 10)。我们生成[0, 10) 之间的随机数，随机数落到对应的区间，我们就选择对应的服务器来处理请求。
    - 加权轮询负载均衡
      - 轮询就是把请求依次分配给每个服务提供者。加权轮询就是在轮询的基础上，让更多的请求落到权重更大的服务提供者上。
      - 假如有两个提供相同服务的服务器 S1,S2，S1 的权重为 7，S2 的权重为 3。如果我们有 10 次请求，那么 7 次会被 S1 处理，3 次被 S2 处理。
    - 最小活跃数负载均衡
      - 每收到一个请求后，对应的服务提供者的活跃数 +1，当这个请求处理完之后，活跃数 -1。
      - 谁的活跃数越少，谁的处理速度就越快，性能也越好，这样的话，我就优先把请求给活跃数少的服务提供者处理。
      - 如果有多个服务提供者的活跃数相等怎么办？很简单，那就再走一遍 加权随机算法。
    - 一致性 Hash 负载均衡策略
      - 由请求的参数决定的，也就是说相同参数的请求总是发到同一个服务提供者。
34. ZooKeeper 应用场景
    - 命名服务：可以通过 ZooKeeper 的顺序节点生成全局唯一 ID。
    - 数据发布/订阅：通过 Watcher 机制 可以很方便地实现数据发布/订阅。当你将数据发布到 ZooKeeper 被监听的节点上，其他机器可通过监听 ZooKeeper 上节点的变化来实现配置的动态更新。
    - 分布式锁：通过创建唯一节点获得分布式锁
35. ZooKeeper 集群角色
    - Leader 既可以为客户端提供写服务又能提供读服务。
    - 除了 Leader 外，Follower 和 Observer 都只能提供读服务。
    - Follower 和 Observer 唯一的区别在于 Observer 机器不参与 Leader 的选举过程，也不参与写操作的“过半写成功”策略，因此 Observer 机器可以在不影响写性能的情况下提升集群的读性能
36. ZooKeeper 集群为啥最好奇数台？
    - ZooKeeper 集群在宕掉几个 ZooKeeper 服务器之后，如果剩下的 ZooKeeper 服务器个数大于宕掉的个数的话整个 ZooKeeper 才依然可用。
    - 2n 和 2n-1 的容忍度是一样的，都是 n-1，何必增加那一个不必要的 ZooKeeper 呢
37. ZooKeeper 选举的过半机制防止脑裂
    - 对于一个集群，通常多台机器会部署在不同机房，来提高这个集群的可用性。保证可用性的同时，会发生一种机房间网络线路故障，导致机房间网络不通，而集群被割裂成几个小集群。这时候子集群各自选主导致“脑裂”的情况。
    - ZooKeeper 的过半机制导致不可能产生 2 个 leader，因为少于等于一半是不可能产生 leader 的，这就使得不论机房的机器如何分配都不可能发生脑裂。
38. 2PC（两阶段提交）
    - 单点故障问题，如果协调者挂了那么整个系统都处于不可用的状态了。
    - 阻塞问题，即当协调者发送 prepare 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能。
    - 数据不一致问题，比如当第二阶段，协调者只发送了一部分的 commit 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题
39. 3PC（三阶段提交）
    - 3PC 在很多地方进行了超时中断的处理，比如协调者在指定时间内未收到全部的确认消息则进行事务中断的处理，这样能 减少同步阻塞的时间 。
    - 还有需要注意的是，3PC 在 DoCommit 阶段参与者如未收到协调者发送的提交事务的请求，它会在一定时间内进行事务的提交。
    - 为什么这么做呢？是因为这个时候我们肯定保证了在第一阶段所有的协调者全部返回了可以执行事务的响应，这个时候我们有理由相信其他系统都能进行事务的执行和提交，所以不管协调者有没有发消息给参与者，进入第三阶段参与者都会进行事务的提交操作。
40. K8s 微服务架构 //todo
41. 负载均衡常见的算法
    - 随机法 两次随机法
    - 轮询法
    - 哈希法 一致性 Hash 法
    - 最小连接法 最少活跃法 最快响应时间法
42. Docker和K8s的关系
    - Docker是一个轻量级的容器化平台，它允许开发人员将应用程序和其依赖项打包为可移植的容器镜像，并在不同的环境中进行部署。
    - Kubernetes是一个开源的容器编排工具，用于自动化应用程序的部署、伸缩和管理。它提供了高度可靠性的容器集群，并具有自动扩展、负载平衡和故障恢复的功能。
43. Istio服务网格是什么
    - 在Kubernetes的基础上，以非侵入的方式为运行在集群中的微服务提供流量管理、安全加固、服务监控和策略管理等功能。
    - 在数据平面由一组和业务服务成对出现的 Sidecar 代理（Envoy）构成，它的主要功能是接管服务的进出流量
    - 边车模式 (Sidecar)：Istio 会在每一个 Pod 旁边强行塞进一个 Envoy 代理。Pod 就不再直接收发流量了，所有流量都要经过 Envoy
    - 一个 Pod 内部运行了 2 个容器
      - 一个是 Spring Boot 业务容器
      - 一个是 Istio 自动注入的 Envoy Sidecar 代理容器。 由于所有流量都要经过 Sidecar，只有两个容器都 Ready，Pod 才算真正可用
    - 在 没有 Istio 之前流量路径是： Nginx Ingress -> Service -> Pod 
    - 在 有了 Istio 之后，Istio 接管了所有的环节： Istio Gateway (入口 Envoy) -> Service -> Istio Sidecar (Pod 里的 Envoy) -> Pod
44. VirtualService是什么
    - VirtualService是Istio流量治理的一个核心配置，通过VirtualService，用户可以指定如何将请求路由到目标服务的不同版本和子集，从而实现流量治理的各种需求。
    - 通过定义路由目标，可以实现诸如蓝绿部署、金丝雀发布等流量治理策略。
45. Jenkins、Pipeline
    - 流水线（Pipeline）是一种可编排的持续集成和交付（CI/CD）方法，它以代码的方式定义整个软件开发过程中的构建、测试和部署流程。
    - Pipeline 插件是 Jenkins 的默认安装插件之一，通常在安装 Jenkins 后就会自动包含。是基于 Groovy 语言的。
46. etcd是什么
    - etcd 是基于 Go 语言编写的分布式、高可用的 键值存储（Key-Value Store） 系统
    - 基于 Raft 算法，保证在集群环境下数据的一致性
    - Watch 机制：客户端可以监听某个 Key 的变化，一旦数据更新，etcd 会秒级主动推送给客户端
    - etcd 是 K8s 唯一的元数据存储后端，所有的 Pod 状态、配置信息（ConfigMap/Secret）、节点信息都存在 etcd 中
    - 通过 etcd 的 Watch 机制，APISIX 可以在毫秒内感知路由或插件配置的变更
47. WebAssembly解决了什么问题
    - 在分布式架构中，Wasm 解决了一个大难题：插件系统的多语言支持
    - 网关提供一个 Wasm Runtime。 
    - 你用自己熟悉的 Java/Rust/C++ 写好逻辑。 
    - 编译成 .wasm 注入网关。 
    - 网关以几乎原生的速度运行你的逻辑，且即便你的插件写挂了，也只会在沙箱里崩溃，不会导致网关主进程宕机。
48. K8s 核心概念
    - **Pod**：Kubernetes 中最小的部署和调度单元。一个 Pod 包含一个或多个紧密关联的容器，它们共享同一个网络命名空间、存储卷和 IP 地址。
    - **Service**：为一组功能相同的 Pod 提供一个统一的、稳定的访问入口（固定的虚拟 IP 和 DNS 名称）。Service 负责将请求负载均衡到后端的 Pod 上，屏蔽了 Pod 的动态变化和 IP 地址不固定的问题。
    - **Deployment**：一种更高级的控制器，用于管理 Pod 和 ReplicaSet 的生命周期。它允许你以声明式的方式定义应用的目标状态（比如副本数量、容器镜像版本），并自动地、滚动地将当前状态更新到目标状态。
    - **ReplicaSet**：确保在任何时候都有指定数量的 Pod 副本在运行。它通常不直接使用，而是由 Deployment 来管理。
    - **Namespace**：一种逻辑上的资源隔离机制，用于将一个物理集群划分为多个虚拟集群。不同 Namespace 内的资源（如 Pod, Service）名称可以相同，常用于多租户或环境隔离（开发、测试、生产）。
    - **Ingress**：管理从集群外部到集群内部 Service 的 HTTP/HTTPS 流量。它提供了基于 URL 路径或域名的路由规则、SSL 终止和负载均衡等功能，是服务对外暴露的主要方式。
    - **ConfigMap / Secret**：用于将配置信息和敏感数据（如密码、API 密钥）与容器镜像解耦。它们可以作为环境变量或文件卷挂载到 Pod 中。
49. Azure核心服务有哪些
    - **Compute (计算)**
      - **AKS (Azure Kubernetes Service)**: 托管 K8s，简化容器编排。
      - **Azure Functions**: Serverless 计算，事件驱动。
    - **Storage & Database (存储与数据库)**
      - **Blob Storage**: 对象存储，存海量非结构化数据（类似 S3）。
      - **Azure SQL Database**: 托管 SQL Server。
    - **Networking (网络)**
      - **APIM (API Management)**: 托管的 API 网关。提供统一入口、限流熔断、身份认证（OAuth2）、协议转换等功能。
    - **Messaging (消息)**
      - **Service Bus**: 企业级消息队列（类似 RabbitMQ/ActiveMQ）。
      - **Event Hubs**: 大数据流摄入（类似 Kafka）。
    - **Identity (身份)**
      - **Entra ID (原 Azure AD)**: 身份认证与访问管理。
50. Azure AD 和 Service Principal 的区别
    - **Azure AD (Entra ID)**: 是**身份提供商 (IdP)**，类似于一个包含所有用户和应用的数据库。它管理“谁是谁”。
    - **Service Principal (服务主体)**: 是**非人类账号**（机器人账号）。
      - **场景**: 用于代码、CI/CD 流水线或后台服务访问 Azure 资源。
      - **对比**: User 是给人用的，Service Principal 是给程序用的。
      - **关系**: 先有 **App Registration** (应用定义的蓝图)，在特定租户下实例化后成为 **Service Principal** (实际的身份实体)。
51. Azure 官方推荐的 SPA 托管方案
    - 前端：npm run build打包成SPA → Azure Blob Storage (Static Website) + Azure Front Door / CDN
    - 后端：Spring Boot → Docker Image → ACR → AKS
    - 统一入口：Azure Front Door（HTTPS、WAF、路由、加速），自定义域名应绑定在 Azure Front Door 上，而不是 Blob 上
    - Front Door + CDN 级别 = 数十万到百万级 QPS，且 Front Door 是自动水平扩展的
52. 如何确保“前端页面不会挂掉”
    - 启用 Front Door CDN：静态资源直接命中 Edge，绝大多数请求不会回源 Blob
    - 合理的缓存策略，Cache-Control: public, max-age=31536000, immutable
    - 多 Region Blob，Front Door 支持多 origin，Blob Storage 本身是多副本的（LRS / GRS）
53. SPA 标准登录流程
    - 到 Azure AD 中注册一个 SPA 应用，得到client_id和redirect_uri
    - 前端生成随机密钥，code_verifier = random(43~128 chars)，code_challenge = SHA256(code_verifier)
    - 前端跳转到 Azure AD / B2C：GET /authorize?response_type=code&code_challenge=abc&code_challenge_method=S256
    - 用户登录 / 注册
    - Azure AD 把 challenge 和 code 绑定存储，Redirect 回前端（只有 code）
    - Angular 在后台换 token，POST /token，grant_type=authorization_code&code=abc123&code_verifier=original_random_value
    - Azure AD 返回 access_token
    - 后端Spring Security会通过 Azure 的 JWKS endpoint（issuer-uri） 自动拉取公钥，
    - 验证token的签名，iss（谁签发的）audience（给谁用的，只接受 aud = 自己的 token）
    - Azure AD 是身份提供者（IdP），只提供 user id（oid / sub），业务系统自己维护用户表和权限
54. k8s
    - .\mvnw clean package -DskipTests
    - 准备Dockerfile
    - docker build -t spring-boot-demo:v1 .
      - kind get clusters
      - kind load docker-image spring-boot-demo:v1 --name docker-desktop
    - 导入到第一个工作节点：docker save spring-boot-demo:v1 | docker exec -i desktop-worker ctr -n k8s.io images import -
    - 入到第二个工作节点：docker save spring-boot-demo:v1 | docker exec -i desktop-worker2 ctr -n k8s.io images import -
    - kubectl config current-context 查看当前集群上下文
    - kubectl apply -f deployment.yaml
    - kubectl get pods
    - kubectl port-forward service/spring-boot-service 8080:80
    - kubectl logs -f spring-boot-deployment-89dcc8f5b-66wl8
    - kubectl rollout restart deployment spring-boot-deployment
    - 创建ingress
      - 安装 Ingress控制器 kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml
      - kubectl get pods -n ingress-nginx 等待状态从ContainerCreating到Running
      - 加入Ingress配置后执行 kubectl apply -f deployment.yaml
    - 创建istio
      - github下载安装helm
      - helm repo add istio https://istio-release.storage.googleapis.com/charts
      - helm repo update
      - kubectl create namespace istio-system
      - helm install istio-base istio/base -n istio-system
      - helm install istiod istio/istiod -n istio-system --wait
      - helm install istio-ingress istio/gateway -n istio-system --wait （旧版istio，如果不需要使用virtualService可以跳过，直接使用Gateway API标准）
      - kubectl get svc -n istio-system
      - kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.0.0/standard-install.yaml 安装Gateway API 资源定义（CRDs）
    - 打上注入标签
      - kubectl label namespace default istio-injection=enabled
      - kubectl rollout restart deployment spring-boot-deployment
      - kubectl get gateway spring-boot-gateway -n istio-system 验证PROGRAMMED 变成 True
    - apply yaml, kubectl port-forward -n istio-system svc/spring-boot-gateway-istio 8080:80
55. Kubernetes 和 Docker 的关系
    - Kubernetes 已经不直接依赖 Docker
    - Docker 内部其实包含 containerd。K8s 只是跳过了 Docker 那些花哨的界面和命令行，直接调用了底层的核心组件
    - docker build 出来的不是“Docker 镜像”，而是 “OCI 标准镜像”
    - kubelet 调用底层 containerd 去拉取镜像并启动容器
56. 怎么使用 Nginx Ingress 进行灰度发布
    - 新的代码部署为一个新的 Deployment app-v2 和新的 Service svc-v2
    - 编写一个新的 canary-ingress.yaml
      ```yaml
      annotations:
        nginx.ingress.kubernetes.io/canary: "true"          # 开启灰度功能
        nginx.ingress.kubernetes.io/canary-weight: "10"    # 分配 10% 的流量
      ```
    - 当 Nginx 看到两个 Ingress 绑定同一个域名（localhost）时，如果其中一个标记了 canary: "true"，它就会按照权重进行随机分流
    - 除了权重，还可以根据 Header 分流（比如只有 Headers 里带 Region: Beijing 的人才能看到新版）
57. 